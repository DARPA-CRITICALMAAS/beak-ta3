{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script for performing SOM training and saving results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:#006400; font-family:Computer Modern; font-size:35px; text-align:center; font-weight:bold\">CMASS run SOM clustering method</p>\n",
    "<p style=\"color:#006400; font-family:Computer Modern; font-size:15px; text-align:left; font-weight:bold\">Dr. Ina Storch 06-11-2023 </p>\n",
    "<p style=\"color:#006400; font-family:Computer Modern; font-size:15px; text-align:left; font-weight:bold\">Note: This notebook is designed to run SOM using preprocessed data gained from the datacube from: Lawley et al., 2021. </p>\n",
    "<p style=\"color:#006400; font-family:Computer Modern; font-size:15px; text-align:left; font-weight:bold\">Reference: Lawley, C.J.M., McCafferty, A.E., Graham, G.E., Gadd, M.G., Huston, D.L., Kelley, K.D., Paradis, S., Peter, J.M., and Czarnota, K., 2021. Datasets to support prospectivity modelling for sediment-hosted Zn-Pb mineral systems; Geological Survey of Canada, Open File 8836, 1 .zip file. https://doi.org/10.4095/329203</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nextsomcore.nextsomcore import NxtSomCore\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argsSOM\n",
    "\n",
    "arg = argsSOM.Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Specify parameter for SOM. Input data can eighter be in .lrn file format or .tiff file format. Choose one.\n",
    "\n",
    "The No Data Handeling is not jet implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #------------- \n",
    "# #- Data Input .tiff files:\n",
    "# #------------- \n",
    "# #- If input data is geotiff: list geotiff files, separated by \",\" [\"name1.tiff\",\"name2.tiff\"]\n",
    "# #input_list_text=[\"data/input/70Gravity_Bouguer._norm.tif\",\"data/input/83Magnetic_LongWavelength_HGM._norm.tif\",\"data/input/50Geology_Fault_Proximity._norm.tif\"]\n",
    "# input_list_text=[\"data/input/testdata/Magnetics.tif\",\n",
    "#                 \"data/input/testdata/RockContact(bmgg_bvc).tif\",\n",
    "#                 \"data/input/testdata/RockContact(gsh_bs).tif\",\n",
    "#                 \"data/input/testdata/Unit(bmgg).tif\",\n",
    "#                 \"data/input/testdata/Unit(bvc).tif\",\n",
    "#                 \"data/input/testdata/Unit(gsb).tif\",\n",
    "#                 \"data/input/testdata/Unit(gsh).tif\"\n",
    "#                 ]\n",
    "# arg.input_file= \",\".join(input_list_text)\n",
    "# \n",
    "# arg.geotiff_input=None      # geotiff_input (\"None\", arg.input_file)\n",
    "\n",
    "#------------- \n",
    "#- Or: Data Input .lrn file:\n",
    "#------------- \n",
    "arg.input_file=\"data/input/SOM_grav_mag.lrn\"\n",
    "\n",
    "#-------------\n",
    "#- Data Output\n",
    "#-------------\n",
    "\n",
    "arg.output_folder=\"data/output\"         # Folder to save som dictionary and cluster dictionary\n",
    "\n",
    "arg.output_file_somspace= arg.output_folder+\"/result_som.txt\"   # DO NOT CHANGE! Text file that will contain calculated values: som_x som_y b_data1 b_data2 b_dataN umatrix cluster in geospace.\n",
    "        \n",
    "\n",
    "#-------------\n",
    "#- Parameter\n",
    "#-------------\n",
    "\n",
    "arg.som_x=10                # X dimension of generated SOM\n",
    "arg.som_y=10                # Y dimension of generated SOM\n",
    "arg.epochs=10               # Number of epochs to run\n",
    "\n",
    "# Base parameters required for som calculation. \n",
    "# Additional optional parameters below:\n",
    "arg.outgeofile= arg.output_folder+\"/result_geo.txt\"             # DO NOT CHANGE!\n",
    "arg.output_file_geospace=arg.outgeofile   # Text file that will contain calculated values: {X Y Z} data1 data2 dataN som_x som_y cluster b_data1 b_data2 b_dataN in geospace.\n",
    "\n",
    "arg.kmeans=\"false\"          # Run k-means clustering (true, false)\n",
    "arg.kmeans_init=5           # Number of initializations\n",
    "arg.kmeans_min=2            # Minimum number of k-mean clusters\n",
    "arg.kmeans_max=25           # Maximum number of k-mean clusters\n",
    "\n",
    "arg.neighborhood='gaussian'     # Shape of the neighborhood function. gaussian or bubble\n",
    "arg.std_coeff=0.5               # Coefficient in the Gaussian neighborhood function\n",
    "arg.maptype='toroid'            # Type of SOM (sheet, toroid)\n",
    "arg.initialcodebook=None        # File path of initial codebook, 2D numpy.array of float32.\n",
    "arg.radius0=0                   # Initial size of the neighborhood\n",
    "arg.radiusN=1                   # Final size of the neighborhood\n",
    "arg.radiuscooling='linear'      # Function that defines the decrease in the neighborhood size as the training proceeds (linear, exponential)\n",
    "arg.scalecooling='linear'       # Function that defines the decrease in the learning scale as the training proceeds (linear, exponential)\n",
    "arg.scale0=0.1                  # Initial learning rate\n",
    "arg.scaleN=0.01                 # Final learning rate\n",
    "arg.initialization='random'     # Type of SOM initialization (random, pca)\n",
    "arg.gridtype='rectangular'      # Type of SOM grid (hexagonal, rectangular)\n",
    "#arg.xmlfile=\"none\"              # SOM inputs as an xml file\n",
    "\n",
    "arg.normalized=\"false\"      # Whether the data has been normalized or not (true, false)\n",
    "arg.minN=0                  # Minimum value for normalization\n",
    "arg.maxN=1                  # Maximum value for normalization\n",
    "arg.label=None              # Whether data contains label column, true or false\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/input/SOM_12layer.lrn\n"
     ]
    }
   ],
   "source": [
    "print(arg.input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Run SOM with parameters specified above and save the results. Uses NxtSomCore package to do the actual work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100% [===================================================]\n",
      "data/output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time for epoch 1: 0.3402 Time for epoch 2: 0.3117 Time for epoch 3: 0.3155 Time for epoch 4: 0.2956 Time for epoch 5: 0.3158 Time for epoch 6: 0.3051 Time for epoch 7: 0.3321 Time for epoch 8: 0.3031 Time for epoch 9: 0.2714 Time for epoch 10: 0.2966 "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string '-156,55' to float32 at row 0, column 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/methods/methods/som/run_nextsomcore.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6265616b2d7461332d646576227d/methods/methods/som/run_nextsomcore.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfunctions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdo_nextsomcore_save_results\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdnsr\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6265616b2d7461332d646576227d/methods/methods/som/run_nextsomcore.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m dnsr\u001b[39m.\u001b[39;49mrun_SOM(arg)\n",
      "File \u001b[0;32m/methods/methods/som/functions/do_nextsomcore_save_results.py:37\u001b[0m, in \u001b[0;36mrun_SOM\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     34\u001b[0m     som[\u001b[39m'\u001b[39m\u001b[39mclusters\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mnxtsomcore\u001b[39m.\u001b[39mclusters(som,args\u001b[39m.\u001b[39mkmeans_min,args\u001b[39m.\u001b[39mkmeans_max,args\u001b[39m.\u001b[39mkmeans_init,output_folder)     \n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39moutgeofile \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m     nxtsomcore\u001b[39m.\u001b[39;49msave_geospace_result(args\u001b[39m.\u001b[39;49moutgeofile, header, som, output_folder, args\u001b[39m.\u001b[39;49minput_file, args\u001b[39m.\u001b[39;49mnormalized, args\u001b[39m.\u001b[39;49mlabel) \n\u001b[1;32m     39\u001b[0m nxtsomcore\u001b[39m.\u001b[39msave_somspace_result(args\u001b[39m.\u001b[39moutput_file_somspace, header, som, output_folder, args\u001b[39m.\u001b[39minput_file, args\u001b[39m.\u001b[39mnormalized)  \n\u001b[1;32m     40\u001b[0m \u001b[39mif\u001b[39;00m(args\u001b[39m.\u001b[39mgeotiff_input \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n",
      "File \u001b[0;32m/methods/methods/som/nextsomcore/nextsomcore.py:181\u001b[0m, in \u001b[0;36mNxtSomCore.save_geospace_result\u001b[0;34m(self, output_file, header, som, output_folder, input_file, normalized, labelIndex)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_geospace_result\u001b[39m(\u001b[39mself\u001b[39m, output_file, header, som, output_folder, input_file, normalized\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, labelIndex\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m):\n\u001b[1;32m    163\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Write SOM results with header line and input columns to disk in geospace\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \n\u001b[1;32m    165\u001b[0m \u001b[39m    Output file columns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39m    :type som: dictionary.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m     coord_cols \u001b[39m=\u001b[39m read_coordinate_columns(header)\n\u001b[1;32m    182\u001b[0m     data_cols \u001b[39m=\u001b[39m read_data_columns(header)\n\u001b[1;32m    183\u001b[0m     som_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extract_som_cols_geospace(som, data_cols[\u001b[39m'\u001b[39m\u001b[39mcolnames\u001b[39m\u001b[39m'\u001b[39m])   \n",
      "File \u001b[0;32m/methods/methods/som/nextsomcore/loadfile.py:34\u001b[0m, in \u001b[0;36mread_coordinate_columns\u001b[0;34m(header)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_coordinate_columns\u001b[39m(header):   \n\u001b[1;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m(header[\u001b[39m'\u001b[39m\u001b[39mfiletype\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlrn\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> 34\u001b[0m         coords\u001b[39m=\u001b[39mread_lrn_coordinate_columns(header)    \n\u001b[1;32m     35\u001b[0m         \u001b[39mreturn\u001b[39;00m coords\n\u001b[1;32m     36\u001b[0m     \u001b[39melif\u001b[39;00m(header[\u001b[39m'\u001b[39m\u001b[39mfiletype\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcsv\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/methods/methods/som/nextsomcore/lrnfile.py:62\u001b[0m, in \u001b[0;36mread_lrn_coordinate_columns\u001b[0;34m(lrn_header)\u001b[0m\n\u001b[1;32m     60\u001b[0m coord_cols \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i, x \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(lrn_header[\u001b[39m'\u001b[39m\u001b[39mcoltypes\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mif\u001b[39;00m x \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m lrn_header[\u001b[39m'\u001b[39m\u001b[39mcolnames\u001b[39m\u001b[39m'\u001b[39m][i]\u001b[39m.\u001b[39mupper() \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mZ\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m     61\u001b[0m fmt \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(coord_cols))\u001b[39m.\u001b[39mrstrip()\n\u001b[0;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m _read_columns(lrn_header, coord_cols, fmt)\n",
      "File \u001b[0;32m/methods/methods/som/nextsomcore/lrnfile.py:73\u001b[0m, in \u001b[0;36m_read_columns\u001b[0;34m(lrn_header, columns, fmt)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mInvalid type: columns must be a list or tuple\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     72\u001b[0m colnames \u001b[39m=\u001b[39m ([lrn_header[\u001b[39m'\u001b[39m\u001b[39mcolnames\u001b[39m\u001b[39m'\u001b[39m][i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m columns])\n\u001b[0;32m---> 73\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mloadtxt(\n\u001b[1;32m     74\u001b[0m             lrn_header[\u001b[39m'\u001b[39;49m\u001b[39mfile\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     75\u001b[0m             dtype\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfloat32\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     76\u001b[0m             delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     77\u001b[0m             skiprows\u001b[39m=\u001b[39;49mlrn_header[\u001b[39m'\u001b[39;49m\u001b[39mheaderlength\u001b[39;49m\u001b[39m'\u001b[39;49m] , \n\u001b[1;32m     78\u001b[0m             usecols\u001b[39m=\u001b[39;49m(columns))\n\u001b[1;32m     79\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m: data, \u001b[39m'\u001b[39m\u001b[39mcolnames\u001b[39m\u001b[39m'\u001b[39m: colnames, \u001b[39m'\u001b[39m\u001b[39mfmt\u001b[39m\u001b[39m'\u001b[39m: fmt}\n",
      "File \u001b[0;32m/opt/conda/envs/dev-env/lib/python3.9/site-packages/numpy/lib/npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delimiter, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1371\u001b[0m     delimiter \u001b[39m=\u001b[39m delimiter\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1373\u001b[0m arr \u001b[39m=\u001b[39m _read(fname, dtype\u001b[39m=\u001b[39;49mdtype, comment\u001b[39m=\u001b[39;49mcomment, delimiter\u001b[39m=\u001b[39;49mdelimiter,\n\u001b[1;32m   1374\u001b[0m             converters\u001b[39m=\u001b[39;49mconverters, skiplines\u001b[39m=\u001b[39;49mskiprows, usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[1;32m   1375\u001b[0m             unpack\u001b[39m=\u001b[39;49munpack, ndmin\u001b[39m=\u001b[39;49mndmin, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1376\u001b[0m             max_rows\u001b[39m=\u001b[39;49mmax_rows, quote\u001b[39m=\u001b[39;49mquotechar)\n\u001b[1;32m   1378\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m/opt/conda/envs/dev-env/lib/python3.9/site-packages/numpy/lib/npyio.py:1016\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     data \u001b[39m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[1;32m   1015\u001b[0m \u001b[39mif\u001b[39;00m read_dtype_via_object_chunks \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1016\u001b[0m     arr \u001b[39m=\u001b[39m _load_from_filelike(\n\u001b[1;32m   1017\u001b[0m         data, delimiter\u001b[39m=\u001b[39;49mdelimiter, comment\u001b[39m=\u001b[39;49mcomment, quote\u001b[39m=\u001b[39;49mquote,\n\u001b[1;32m   1018\u001b[0m         imaginary_unit\u001b[39m=\u001b[39;49mimaginary_unit,\n\u001b[1;32m   1019\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols, skiplines\u001b[39m=\u001b[39;49mskiplines, max_rows\u001b[39m=\u001b[39;49mmax_rows,\n\u001b[1;32m   1020\u001b[0m         converters\u001b[39m=\u001b[39;49mconverters, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1021\u001b[0m         encoding\u001b[39m=\u001b[39;49mencoding, filelike\u001b[39m=\u001b[39;49mfilelike,\n\u001b[1;32m   1022\u001b[0m         byte_converters\u001b[39m=\u001b[39;49mbyte_converters)\n\u001b[1;32m   1024\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[39m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[39m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m     \u001b[39m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m     \u001b[39m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m     \u001b[39mif\u001b[39;00m filelike:\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string '-156,55' to float32 at row 0, column 2."
     ]
    }
   ],
   "source": [
    "import functions.do_nextsomcore_save_results as dnsr\n",
    "\n",
    "dnsr.run_SOM(arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Plot Results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functions.argsPlot\n",
    "#\n",
    "#argsP = functions.argsPlot.Args()\n",
    "#\n",
    "#argsP.outsomfile= \"data/output/somspace.txt\"   # som calculation somspace output text file\n",
    "#argsP.som_x= 100                 # som x dimension\n",
    "#argsP.som_y= 100                 # som y dimension\n",
    "#argsP.input_file= \"data/input/SOM_grav_mag.lrn\"    # Input file(*.lrn)\n",
    "#argsP.dir= \"data/output\"        # Input file(*.lrn) or directory where som.dictionary was safet to (/output/som.dictionary)\n",
    "#argsP.grid_type= 'rectangular'  # grid type (square or hexa), (rectangular or hexagonal)\n",
    "#argsP.redraw='true'             # whether to draw all plots, or only those required for clustering (true: draw all. false:draw only for clustering).\n",
    "#argsP.outgeofile='data/output/geospace.txt'     # som geospace results txt file\n",
    "#argsP.dataType=None             # Data type (scatter or grid)\n",
    "#argsP.noDataValue='NA'          # noData value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoSpace plots finished\n",
      "SomSpace plots finshed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/dev-env/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/opt/conda/envs/dev-env/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/opt/conda/envs/dev-env/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/opt/conda/envs/dev-env/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/opt/conda/envs/dev-env/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/opt/conda/envs/dev-env/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/opt/conda/envs/dev-env/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/opt/conda/envs/dev-env/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/opt/conda/envs/dev-env/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/opt/conda/envs/dev-env/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/opt/conda/envs/dev-env/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/opt/conda/envs/dev-env/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxplots finished\n"
     ]
    }
   ],
   "source": [
    "run functions/plot_som_results.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
